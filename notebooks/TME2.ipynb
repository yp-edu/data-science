{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis\n",
        "\n",
        "\n",
        "The objective of this notebook is to explore datasets.\n",
        "You will need Pandas, a tutorial is available [here](https://pandas.pydata.org/docs/user_guide/10min.html).\n",
        "\n",
        "\n",
        "Please note that this notebook is inspired from notebooks published by Galiana, Lino. 2023. Python Pour La Data Science. https://doi.org/10.5281/zenodo.8229676."
      ],
      "metadata": {
        "id": "snhL9W6GUFhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "We consider a dataset gathering information about elections and votes between 2018 and 2022 in the USA. Il also maps economics signals."
      ],
      "metadata": {
        "id": "NhazNolEWedh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q23PofkyPqAS"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/linogaliana/python-datascientist/master/content/modelisation/get_data.py'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('getdata.py', 'wb').write(r.content)\n",
        "\n",
        "import getdata\n",
        "votes = getdata.create_votes_dataframes()\n",
        "votes.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is the size of the dataframe? (number of lines and columns)\n",
        "\n",
        "Print the column names and their types.\n",
        "\n",
        "Print the statistics of each numerical column (mean, std, quartile, min, max)."
      ],
      "metadata": {
        "id": "wBFIQH6CtRor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#[STUDENT]\n"
      ],
      "metadata": {
        "id": "UDNUUlvCs1Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2. What are the different values of the 'winner' variable? Recode this values into numbers 1,2,3,... and store this encoding in a new variable \"winner2\"."
      ],
      "metadata": {
        "id": "fqERsYEO0ufg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#[STUDENT\n"
      ],
      "metadata": {
        "id": "q7Lqo9R31AuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descriptive analysis\n",
        "\n",
        "\n",
        "Q3. Create a dataframe including only the following variables: \"winner2\", \"votes_gop\",\n",
        "          'Unemployment_rate_2021', 'Median_Household_Income_2021',\n",
        "          'Percent of adults with less than a high school diploma, 2018-22',\n",
        "          \"Percent of adults with a bachelor's degree or higher, 2018-22\".\n",
        "Keep the index \"GEOID\" as index of your dataframe. For this, use the:\n",
        "- ```set_index(...)``` https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html\n",
        "function\n",
        "\n",
        "Also, rename the \"winner2\" variable with \"winner\" in the new data frame. This can be done with:\n",
        "- ```df2.rename(columns={'oldColumnName: 'newColumnName}, inplace=True)```\n",
        "\n",
        "We will refer to the reduced data frame as ```df2```. Display the first 3 columns of the new data.\n"
      ],
      "metadata": {
        "id": "A68TVqNhaLAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#[STUDENT\n"
      ],
      "metadata": {
        "id": "CTmkHPsTFOw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Create a frequency tab for each winner value. Build the plot with horizontal bars illustrating this frequency. For this, you can use the:\n",
        "- ```.plot(...)``` https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n",
        "function, which belongs to data frames. To create the frequency tab, the following function is useful:\n",
        "- ```.value_counts()``` https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html\n"
      ],
      "metadata": {
        "id": "OK8n-qgK1zVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#[STUDENT"
      ],
      "metadata": {
        "id": "PmJRu1Kg11mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Let's consider the 'Median_Household_Income_2021' variable. Transform this variable into a categorical one with 5 five labels, and store it in a new column of ```df2``` named \"Median_Household_Income_2021_cat\". Create the frequency table and the associated bar plot.\n",
        "\n",
        "For this, you can use the following function:\n",
        "- ```pd.cut(...)``` https://pandas.pydata.org/docs/reference/api/pandas.cut.html\n",
        "\n",
        "This function converts *continuous* numerical data into cagtegorical data by establishing *bins*, into which the data fall. These bins can be labelled with the function"
      ],
      "metadata": {
        "id": "NjBUKv6j2cjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STUDENT"
      ],
      "metadata": {
        "id": "dDLzqqgf20Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Provide descriptive statistics of all variables in the (reduced) dataframe ```df2```.\n",
        "\n"
      ],
      "metadata": {
        "id": "gdk_6JpAqP5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#[STUDENT]"
      ],
      "metadata": {
        "id": "9FW9acNXqPVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Build a histogram for the variables vote_gop. For this, the following function is useful:\n",
        "- ```.hist(...)``` https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html"
      ],
      "metadata": {
        "id": "By6z3BRhrwb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#[STUDENT]\n",
        "df2['votes_gop'].hist()"
      ],
      "metadata": {
        "id": "6xhXRvImrwMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. Extract the correlation matrix of ```df2```. Before doing this, remove the \"Median_Household_Income_2021_cat\" variable from the ```df2``` data. Why do we have to remove this ? (think about the definition of correlation).\n",
        "- ```.drop(...)``` https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html\n",
        "\n",
        "For the correlation matrix, remember the following function:\n",
        "- ```.corr(...)``` https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\n",
        "\n",
        "Graph it by using the seaborn package and the following function:\n",
        "- ```heatmap()``` https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
        "\n",
        "\n",
        "Plot a matrix of point clouds of df2 variables with:\n",
        "- ```pd.plotting.scatter_matrix``` https://pandas.pydata.org/docs/reference/api/pandas.plotting.scatter_matrix.html\n",
        "Interpret this matrix."
      ],
      "metadata": {
        "id": "O35QIZ1svGhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#[STUDENT]"
      ],
      "metadata": {
        "id": "Yo0UR7MvvG3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization with maps\n",
        "\n",
        "\n",
        "Q9. Below, we have two blocks of code generating two different graphs (the first map is a choropleth card). They use the same dataset but have different shapes. Comment these graphs and the differences."
      ],
      "metadata": {
        "id": "luC6JPCRV6cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# republican : red, democrat : blue\n",
        "color_dict = {'republican': '#FF0000', 'democrats': '#0000FF'}\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (12,12))\n",
        "grouped = votes.groupby('winner')\n",
        "for key, group in grouped:\n",
        "    group.plot(ax=ax, column='winner', label=key, color=color_dict[key])\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "9kBXZhQhYNFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "centroids = votes.copy()\n",
        "centroids.geometry = centroids.centroid\n",
        "centroids['size'] = centroids['CENSUS_2020_POP'] / 10000  # to get reasonable plotable number\n",
        "\n",
        "color_dict = {\"republican\": '#FF0000', 'democrats': '#0000FF'}\n",
        "centroids[\"winner\"] =  np.where(centroids['votes_gop'] > centroids['votes_dem'], 'republican', 'democrats')\n",
        "\n",
        "\n",
        "centroids['lon'] = centroids['geometry'].x\n",
        "centroids['lat'] = centroids['geometry'].y\n",
        "centroids = pd.DataFrame(centroids[[\"county_name\",'lon','lat','winner', 'CENSUS_2020_POP',\"state_name\"]])\n",
        "groups = centroids.groupby('winner')\n",
        "\n",
        "df = centroids.copy()\n",
        "\n",
        "df['color'] = df['winner'].replace(color_dict)\n",
        "df['size'] = df['CENSUS_2020_POP']/6000\n",
        "df['text'] = df['CENSUS_2020_POP'].astype(int).apply(lambda x: '<br>Population: {:,} people'.format(x))\n",
        "df['hover'] = df['county_name'].astype(str) +  df['state_name'].apply(lambda x: ' ({}) '.format(x)) + df['text']\n",
        "\n",
        "fig_plotly = go.Figure(\n",
        "  data=go.Scattergeo(\n",
        "  locationmode = 'USA-states',\n",
        "  lon=df[\"lon\"], lat=df[\"lat\"],\n",
        "  text = df[\"hover\"],\n",
        "  mode = 'markers',\n",
        "  marker_color = df[\"color\"],\n",
        "  marker_size = df['size'],\n",
        "  hoverinfo=\"text\"\n",
        "  )\n",
        ")\n",
        "\n",
        "fig_plotly.update_traces(\n",
        "  marker = {'opacity': 0.5, 'line_color': 'rgb(40,40,40)', 'line_width': 0.5, 'sizemode': 'area'}\n",
        ")\n",
        "\n",
        "fig_plotly.update_layout(\n",
        "  title_text = \"Reproduction of the \\\"Acres don't vote, people do\\\" map <br>(Click legend to toggle traces)\",\n",
        "  showlegend = True,\n",
        "  geo = {\"scope\": 'usa', \"landcolor\": 'rgb(217, 217, 217)'}\n",
        ")"
      ],
      "metadata": {
        "id": "gmiHYiXiV3ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization\n",
        "\n",
        "Q10. Standardize all variables in the ```df2``` dataframe, apart from the ```Median_Household_Income_2021_cat``` variable. Do not overwrite the values of the ```df2``` data frame, create another one. For the scaling, look at:\n",
        "- ```StandardScaler()``` https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html (also, see lesson slides)\n",
        "\n",
        "Careful, the function ```scaler.fit_transform``` returns a **numpy** array, and not a pandas data frame. To convert the numpy array back to a data frame, you can use:\n",
        "- ```pd.DataFrame(x, columns = df2.drop(columns=['Median_Household_Income_2021_cat']).columns)```\n",
        "This specifies that the columns in x (which have no labels) are taken to be in  the same order as those of ```df2``` (without the ```Median_Household_Income_2021_cat``` column), and are thus labelled in that order in the resulting data frame.\n"
      ],
      "metadata": {
        "id": "VwiyhCA-x_SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# STUDENT\n"
      ],
      "metadata": {
        "id": "OSiF5yqF8SpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, look at the histograms of variable 'the Median_Household_Income_2021 variable' before/after standardization."
      ],
      "metadata": {
        "id": "A_nPQjUB8vr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STUDENT"
      ],
      "metadata": {
        "id": "upNP3JoD8vyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. Verify that the distribution of \"Median_Household_Income_2021\" is centered at zero, and that the empirical variance is indeed equal to 1."
      ],
      "metadata": {
        "id": "ipfbl_nmya6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#[STUDENT]"
      ],
      "metadata": {
        "id": "5JcDwjz1ylR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12. Create scaler, a function which is built on the first 1000 rows of your ```df2``` DataFrame, with the exception of the ```winner2``` and ```Median_Household_Income_2021_cat``` variables. Hint, the:\n",
        "- ```.iloc([a:b,c:d])```\n",
        "function can be used to specify the rows (between ```a``` and ```b```) and the columns (between ```c``` and ```d```) which define the smaller data frame with the first 1000 rows.\n",
        "\n",
        "Check the mean and standard deviation of each column on these same observations. These are stored in the ```.mean_``` and ```.scale_``` attributes of the scaler."
      ],
      "metadata": {
        "id": "qjjoDKDXylys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STUDENT\n"
      ],
      "metadata": {
        "id": "x9E2riLs8eM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outlier detection\n",
        "\n",
        "Q13. Plot the distribution of each variable in a boxplot and analyze them. Useful function:\n",
        "- ```sns.boxplot(...)``` https://seaborn.pydata.org/generated/seaborn.boxplot.html\n",
        "\n",
        "Do you see outliers?"
      ],
      "metadata": {
        "id": "YKdIsBOK7Lp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STUDENT"
      ],
      "metadata": {
        "id": "_986EJ8o8sCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14. Identify, for each variable, individuals that are not included within the window +/- 3*std. You can remove the following columns: ```'Median_Household_Income_2021_cat', 'winner2','GEOID'```. How many lines would you remove in total?"
      ],
      "metadata": {
        "id": "3Hx_nnk_B4XQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STUDENT\n",
        "\n"
      ],
      "metadata": {
        "id": "u60hJWfR9X_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15. Let's process over all variables with a library: you can import and use the IsolationForest function from the sklearn.ensemble package.\n",
        "Change the different parameter values to identify their impact.\n",
        "Do you obtain results different from the analysis of single variables."
      ],
      "metadata": {
        "id": "wgC_3KK479Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: do it\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Assuming df2 is already defined as in the previous code.\n",
        "\n",
        "# Create an IsolationForest model\n",
        "model = IsolationForest(n_estimators=100, max_samples='auto', contamination='auto', random_state=42)\n",
        "\n",
        "# Fit the model to your data\n",
        "model.fit(df2.drop(columns=['Median_Household_Income_2021_cat', 'winner']))\n",
        "\n",
        "# Get the prediction of the model\n",
        "df2['anomaly'] = model.predict(df2.drop(columns=['Median_Household_Income_2021_cat', 'winner']))\n",
        "\n",
        "# Print the number of anomalies detected by the model\n",
        "print(f\"Number of anomalies detected: {df2[df2['anomaly'] == -1].shape[0]}\")\n"
      ],
      "metadata": {
        "id": "G3HO35gE9qNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q16. Display in a scatter plot variables 'votes_gop' and 'Unemployment_rate_2021' and color points according whether they are outliers or not. Interpret.\n",
        "You can change pairs of variables."
      ],
      "metadata": {
        "id": "0SJF3nxmoaqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STUDENT\n"
      ],
      "metadata": {
        "id": "9PPVj0Rp924z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q17. Display for all pairs of variables using pairplot from seaborn.\n"
      ],
      "metadata": {
        "id": "E1zPj-L4pS8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#[STUDENT]"
      ],
      "metadata": {
        "id": "s6JEsm8Vl8Gz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}