{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf788c0-4a87-427a-9e82-33d890c3e90a",
   "metadata": {},
   "source": [
    "# Lab: machine learning protocol, part 1\n",
    "\n",
    "Author: Alasdair Newson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d6677-84ba-4679-bb1e-a270d171e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# pour eviter les warnings embetants\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5df37f-2dc4-449d-933b-8880a5c18447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2918dabe-57db-4092-97e0-e8cfb32df398",
   "metadata": {},
   "source": [
    "# 1/ Reproduceability and random seeds\n",
    "\n",
    "We saw in the lesson that it was very important to be able to **reproduce** results. To get exactly the same results, in spite of using randomness in an algorithm, we look to **random seeds**. These are integer values which determine a sequence of **pseudo-random numbers** (see lesson).\n",
    "\n",
    "To set this random seed in the numpy framework, we use:\n",
    "- ```np.random.seed(rand_seed)```: https://numpy.org/doc/2.2/reference/random/generated/numpy.random.seed.html\n",
    "  \n",
    "If you put an empty input, then numpy will set the seed itself. It will use information from your computer to do this (that it hopes is random as possible). Use this function now, with a fixed seed, and check that a series of 5 random Gaussian variables is indeed the same each time. Note, to reset the random number generator back to the initial state, you have to set the seed again.\n",
    "\n",
    "After this, use the default random seed (no input to ```np.random.seed```) and check to make sure that the series of random numbers is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06479712-8388-4815-9ab5-e0b3b4974b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d8e480-226f-4f8d-95aa-2625181ab2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e8fd694-f9d6-45a3-a204-919efdda16ba",
   "metadata": {},
   "source": [
    "## 2/ Train, test\n",
    "\n",
    "We saw in the lesson that it is necessary to split up data into:\n",
    "- train data, which we use for training the model (choosing the parameters)\n",
    "- test data, which we use for testing (evaluating) the model. It is crucial that this data not be observed by the model during training\n",
    "\n",
    "First let us create some random, 2D, data $X$ and binary labels $Y$. These data will contain two subsets of Gaussian data, one centred at:\n",
    "- $\\mu_1 = (0,0)$ with label 0\n",
    "and one centred at:\n",
    "- $\\mu_2 = (2,2)$ with label 1\n",
    "\n",
    "This can be done with the following function:\n",
    "\n",
    "```make_blobs```: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html\n",
    "\n",
    "Create this data now, with a total of $n=1000$ samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da7eb0-58e4-484a-9db4-c14e5b21eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a1e81-e38f-4d13-9b77-1a90336900d1",
   "metadata": {},
   "source": [
    "Now, use a scatter plot to display the data in $X$. Colour the data using the labels (blue for label 0 and red for label 1, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf9b63d-4b6f-4ac3-bb87-ed1bb31127c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526843b3-e432-439b-a508-2a0677ad3aca",
   "metadata": {},
   "source": [
    "Now we are ready to separate the data into train and test. There is a function to do this in scikit-learn:\n",
    "```from sklearn.model_selection import train_test_split``` https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "Use the following (common) split:\n",
    "- $80\\%$ train\n",
    "- $20\\%$ test\n",
    "\n",
    "Carry out the split, and check that the percentages are indeed respected. Display the train data with a scatter plot and verify visually that it indeed ressembles the original data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b81c28a-c5f3-4411-992f-bb08dad041c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa2b4ca-b79c-4960-a7eb-9c5a2e1a5eca",
   "metadata": {},
   "source": [
    "## 2.1 Standard classification pipeline\n",
    "\n",
    "Let's say we wish to classify the above data. There are two classes, so it is a binary classification problem. There is a general syntax for using machine learning models for prediction in scikit-learn. Imagine there is a machine learning algorithm called \"toto\". To import, train and predict using a toto-type model, we would use the following syntax.\n",
    "\n",
    "```\n",
    "from sklearn.TotoClass import Toto\n",
    "my_toto = Toto(arguments)\n",
    "my_toto.fit(X,Y)\n",
    "my_toto.predict(X)\n",
    "```\n",
    "\n",
    "Let's try to do the classification with a \"Support Vector Machine\". This is a classifier which attempts to separate data by drawing a line (in fact a hyperplane) between the two classes. To do this, use the following class:\n",
    "```\n",
    "SVC(kernel=\"linear\")\n",
    "```\n",
    "Carry out the classification and compare your prediction, visually (with two subplots, for example), with the ground truth, on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19004e-ed75-43a2-bfde-f0f1ae50e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4782dd-b31e-41d8-ac80-f18c8e4eb65f",
   "metadata": {},
   "source": [
    "Are these visual results coherent with the intuitive idea of how the SVM works ?\n",
    "\n",
    "Now, we need a more rigorous evaluation of the results. To do this, we will use the prediction accuracy. This is defined as:\n",
    "\n",
    "- $\\frac{\\# \\mathrm{good~predictions} }{\\# \\mathrm{total~predictions}}$\n",
    "\n",
    "This can be calculated with:\n",
    "```from sklearn.metrics import accuracy_score```\n",
    "\n",
    "Do this evaluation now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499be9c2-8d48-41e1-870e-0a09d6522621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a15be9-cc30-4aad-a01e-217fc74fa557",
   "metadata": {},
   "source": [
    "We saw in the lesson that, in order to estimate the performance of a classification algorithm, it is necessary to split the data up further into train, validation and test. Indeed, in most applications, we consider that we do not have access to the test data. Therefore, we use part of the train data as a simulation of \"test\" data. This is named validation data.\n",
    "\n",
    "However, we need a robust evaluation of the performance (we might get unlucky/lucky with the train/validation split). For this, we use ``k-fold validation''. This consists in splitting the train data into several groups, and using one of those groups as validation, and then rotatiing the group used for validation. The model is re-trained each time.\n",
    "\n",
    "This is obviously quite labour-intensive, but can be done with the following function\n",
    "```cross_val_score(...)```: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "\n",
    "Do this now and display the scores and their statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506f09d-a7c2-40cd-8ef3-49f8c4a00e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0324158-c8f5-455c-b104-173b004464df",
   "metadata": {},
   "source": [
    "In general, more data gives more robust estimates of performance. To test this hypothesis, re-produce the whole process (create data, train-test split, and k-fold validation), now with $n=10000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4acf68-1973-4f20-bf80-c04ad0cbe0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2676a33e-3324-417a-8ef3-4730c1e07b7f",
   "metadata": {},
   "source": [
    "Does this confirm the hypothesis (more data gives more robust performance estimation) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f0004-b159-4303-8dc9-4760dc4dde37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "017eb0eb-2df7-424f-936f-a71e3ba25271",
   "metadata": {},
   "source": [
    "What do you think of this result ? Do you think the performance estimation is reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be0f458-7946-41fe-a2ef-274af6341db1",
   "metadata": {},
   "source": [
    "## 3/ Overfitting and regularisation\n",
    "\n",
    "In this section, we are going to look at the problem of **overfitting**. As explained in the lesson, this happens when a machine learning model is so well-trained on the test dataset, that it cannot generalise well to the test dataset. It happens in particular when we allow the model to have a lot of parameters.\n",
    "\n",
    "Let us illustrate this on a regresion problem. First, we create some data, which we will try to regress (predict). This data will represent a quadratic function, perturbed by some \"noise\" $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$:\n",
    "- $Y = a_0+a_1 X+ a_2 X^2 + \\epsilon$\n",
    "\n",
    "where $X\\in \\mathbb{R}$. Logically, we know that the solution should be a quadratic polynomial, but as we will see, the situation may be more complicated due to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de0a347-b427-4e26-b7d0-27d9ee651aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE IS GIVEN\n",
    "x_min = -5.\n",
    "x_max = 5.\n",
    "sigma = 1.5\n",
    "a_0 = 0\n",
    "a_1 = 1\n",
    "a_2 = 1\n",
    "n=50\n",
    "\n",
    "\n",
    "X = np.linspace(x_min,x_max,n)\n",
    "Y = a_0 + a_1*X + a_2*np.power(X,2)\n",
    "X = np.reshape(X,(n,1))\n",
    "# add some noise to make the problem more difficult\n",
    "np.random.seed(5) \n",
    "Y = Y+sigma*np.random.randn(n)\n",
    "plt.scatter(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55be8d89-1526-467f-bab9-b9699f6620f5",
   "metadata": {},
   "source": [
    "Now, we are going to create a polynomial model using Ordinary Least Squares (sometimes this is referred to a polynomial regression). Let $k$ be the order of the polynomial. Although we know that $k$ should be equal to 2, we will pretend we do not know this.\n",
    "\n",
    "In this context, the exponents of $X$ ($X**0, X**1, X**2, X**3$, etc) represent the **features** which we will use for the model, and the $a_0, a_1, a_2$, etc) are the parameters of the model. Notice that, in this sense, the model is linear: the prediction is just a linear combination of the input features. For example, using a polynomial of order 3:\n",
    "$Y = a_0+a_1X+a_2X**2+a_3X**3$\n",
    "In fact, the features could be anything ($\\cos(X), \\exp(X)$ etc), and the model would still be \"linear\" in this sense (we still have an OLS).\n",
    "\n",
    "So now, let us create the polynomial features of $X$. This can be done with the following syntax:\n",
    "\n",
    "```\n",
    "poly = PolynomialFeatures(k,include_bias=True)\n",
    "poly_features = poly.fit_transform(X)\n",
    "```\n",
    "\n",
    "Create these features now, using order $k=2$ (the theoretical value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6976f705-4ad1-46ae-8c28-38e93b789f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7193815b-fb9a-444b-9764-06b16323cbfe",
   "metadata": {},
   "source": [
    "Now, we carry out the OLS (using the data in $X$ for the moment, no train/test). This is done by calling the the ```LinearRegression()``` function of scikit-learn. Use the syntax given above in the \"toto\" model, and replace toto with the linear regressor. Carry out the prediction and call this estimation ```Y_hat```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f90c3-556f-42d9-94b7-683cb35d86d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a9838-98d7-470b-86f0-25e852244e12",
   "metadata": {},
   "source": [
    "Now, we wish to evaluate the model. Since the problem is one of regression, we use the mean squared error (MSE) as a metric. This can be accessed with:\n",
    "\n",
    "- ```from sklearn.metrics import mean_squared_error```\n",
    "\n",
    "Evaluate the MSE of your prediction with the polynomial model (with $k=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d71f42-9f02-4a40-bea8-d229752055f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207bef6a-ddfa-4448-838f-a45dd00f1b7c",
   "metadata": {},
   "source": [
    "Now, do the same regression, except increase the order of the polynomial to $k=20$. What do you notice ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c904dd7a-f5d7-4e0d-b935-bbdd08bbb730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25959560-988a-4f35-a068-1f0f44921b83",
   "metadata": {},
   "source": [
    "So, it looks like we can just increase the model order to get better results ! But of course, we ignored one important aspect: train and test. To evaluate if our model is really better (that is to say, it generalises better), we need to fit on the train data, and predict/evaluate on the test data. Split the data up into train and test now, as above (same splits). In this section of the lab work, we do not worry about validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8458fc0d-4528-44a8-9a55-fee478a39653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e58506a-e2dc-486b-b83c-203e3df0e93d",
   "metadata": {},
   "source": [
    "Now, re-write your code such that the model is fitted on the train data, and predicted/evaluated on the test data. If you wish, you can create a function to do this so you do not have to re-code it many times.\n",
    "\n",
    "Once you have done this, evaluate the model using different values of $k$. What do you find is the best one ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc77ac3-4a0c-4089-a7e9-e4d3678fd99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624415e-d0e9-4f48-b1c5-837fa10b42d9",
   "metadata": {},
   "source": [
    "What is your conclusion now on the best model to use ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3bfaec-388d-4191-a353-697855874c82",
   "metadata": {},
   "source": [
    "## 3.1 Regularisation\n",
    "\n",
    "This situation is quite simple, since we know that the polynomial should be quadratic. However, in many machine learning situations, we want to give the model the flexibility to use many parameters if it needs to, but at the same time ask it to not use them unless necessary. This idea is implemented using \"regularisation\", as seen in the lesson. In practice, this usually means minimising some function $R$ of the parameters $\\theta$.\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta) =  \\sum_i \\lVert Y^{(i)} - f_\\theta(X^{(i)} \\rVert^2_2 + R(\\theta)\n",
    "$$\n",
    "\n",
    "Different functions $R$ are commonly used:\n",
    "- $R(\\theta) = \\sum_i (\\theta_i)^2$: \"Ridge\" regression (also called \"Tikhonov\" regularisation)\n",
    "- $R(\\theta) = \\sum_i |\\theta_i|$: \"Lasso\" regression (or \"l1\" regularisation)\n",
    "\n",
    "These can be implemented, respectively, with the following functions:\n",
    "\n",
    "- ```Ridge```: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "- ```Lasso```: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "\n",
    "Use these two now, setting $k=20$, and compare the regression results (standard, ridge and lasso). You can re-define a new function if you wish to take into account the different regularisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f53f9-4fe2-4323-a1a9-f0aeaf106de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1028c4f-8c34-4e69-97c3-ac7aeb7f36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9310f7-ef50-41cd-b3ea-c1f14cf2b2c1",
   "metadata": {},
   "source": [
    "What are your conclusions ? Which regression works the best ? For each model, plot the estimation to see the effect of the regularisation (to do a plot instead of a scatter, you will need to order the elements in ```X_test```, otherwise the plot will be unreadable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf030d00-a3e6-4481-85a4-d708d43f1ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcaab87-f5a2-435b-b4dc-725c20391529",
   "metadata": {},
   "source": [
    "Try and change the regularisation parameter ($\\alpha$) of the ridge and lasso regressions to see the effect of increasing the regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96533b6-f999-4bce-a669-e23c635ddba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12314b07-3ed0-4cc6-b08b-2a2f634af6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
